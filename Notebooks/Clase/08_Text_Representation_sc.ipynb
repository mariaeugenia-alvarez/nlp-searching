{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDjuOaIfmUiQ"
      },
      "source": [
        "# Introducción\n",
        "\n",
        "Cuando trabajamos con texto existen multitud de formas de representar la información.\n",
        "\n",
        "<img src=https://miro.medium.com/max/904/1*DocMTV7nTAomKxcu3m-tyw.jpeg>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMuXEoTWmUiT"
      },
      "source": [
        "# 1. One-Hot Encoding\n",
        "\n",
        "Antes, introducimos el concepto de **Bag-of-Words**\n",
        "\n",
        "Quizá la forma más sencilla de representar la información. Permite representar cada texto como un vector. Los pasos son los siguientes:\n",
        "\n",
        "1. Definir un **vocabulario** (puede extraerse del corpus)\n",
        "2. Asignamos un entero a cada palabra, de manera que tendremos un vector de longitud igual al número de palabras (cardinalidad) del vocabulario. **Cada posición en el vector representará una palabra del vocabulario**.\n",
        "3. Para cada documento, asignamos en la posición correspondiente del vector pre-construído a cada palabra que lo compone un valor. Dicho valor puede ser si aparece o no (**Term Presence**) o el número de veces que aparece (**Term Frequency**).\n",
        "\n",
        "En su aproximación más simple, **one-hot-encoding**, la codificación se realiza a nivel de token. De esta manera, un documento estará definido por N vectores (tantas como tokens contenga), en las que la posición de cada palabra en cada vector tendrá valor igual a 1 (Term Presence).\n",
        "\n",
        "<img src=https://miro.medium.com/max/1800/1*ArM6Z5jeptCQ082DYn9nDQ.png width=600px>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2E4DxBxmUiU"
      },
      "source": [
        "# 2. Count Vectorizer\n",
        "\n",
        "Convierte una colleción de documentos en una matriz de documentos-palabras. La codificación se realiza, por tanto, a nivel de documento, en lugar de a nivel de token.\n",
        "\n",
        "Al ser un modelo de bag-of-words, **no se codifica la información relativa a la posición de los tokens ni su contexto, solo información a si aparecen y su frecuencia**.\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3HeSb1j_mUiU"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bp2Wg5SEmUiV"
      },
      "outputs": [],
      "source": [
        "sent_1 = 'me gustan los perros'\n",
        "sent_2 = 'hay perros y perros'\n",
        "sent_3 = 'hay muchas razas de perros'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qyfass28mUiW"
      },
      "outputs": [],
      "source": [
        "corpus = [sent_1, sent_2, sent_3]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FN_h5bAemUiW"
      },
      "source": [
        "### Ejemplo básico"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oec7dKr0mUiW"
      },
      "outputs": [],
      "source": [
        "vectorizer = CountVectorizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "indV_WtlmUiW"
      },
      "outputs": [],
      "source": [
        "X = vectorizer.fit_transform(corpus)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(vectorizer.get_feature_names_out())\n",
        "\n"
      ],
      "metadata": {
        "id": "BFHV-6PdtqTX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "doc_term_matrix = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())\n",
        "doc_term_matrix"
      ],
      "metadata": {
        "id": "6QmCiw3Atsx0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LrnHllkmUiY"
      },
      "source": [
        "### Stop words\n",
        "\n",
        "El parámetro `stop_words` acepta:\n",
        "- 'english'\n",
        "- lista de stopwords\n",
        "- None (default), no filtra stop words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lql_idfYmUiY"
      },
      "outputs": [],
      "source": [
        "vectorizer = CountVectorizer(stop_words=['de', 'hay', 'los', 'me'])\n",
        "X = vectorizer.fit_transform(corpus)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(vectorizer.get_feature_names_out())"
      ],
      "metadata": {
        "id": "5HnHacc2tvpX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc_term_matrix = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())\n",
        "doc_term_matrix"
      ],
      "metadata": {
        "id": "OvQAIZuwtymx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6ct9PP5mUiY"
      },
      "source": [
        "### Número máximo de palabras\n",
        "\n",
        "El parámetro `max_features` establece el número máximo de features a extraer (vocabulario). Mantendrá solo el top indicado por dicho parámetro."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T8OaBJLZmUiZ"
      },
      "outputs": [],
      "source": [
        "vectorizer = CountVectorizer(max_features=4)\n",
        "X = vectorizer.fit_transform(corpus)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(vectorizer.get_feature_names_out())"
      ],
      "metadata": {
        "id": "ouLEO3xTt1h5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc_term_matrix = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())\n",
        "doc_term_matrix"
      ],
      "metadata": {
        "id": "xp5vTWirt3we"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FdpotWR3mUiZ"
      },
      "source": [
        "### N-grams como features\n",
        "\n",
        "El parámetro `ngram_range` (tupla) permite definir los valores de `n` para los ngrams (mínimo y máximo) que serán calculados. Por defecto `ngram_range=(1, 1)` (solo palabras)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7wLfMXlpmUiZ"
      },
      "outputs": [],
      "source": [
        "vectorizer = CountVectorizer(ngram_range=(2, 3))  # Jugar con los valores\n",
        "X = vectorizer.fit_transform(corpus)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(vectorizer.get_feature_names_out())"
      ],
      "metadata": {
        "id": "VxVPnKD1t6Qn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc_term_matrix = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())\n",
        "doc_term_matrix"
      ],
      "metadata": {
        "id": "uCRs8B85t81j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ukke71LzmUiZ"
      },
      "source": [
        "### max_df y min_df\n",
        "\n",
        "Límites superior (`max_df`) e inferior (`min_df`). Pueden definirse como `float` (de 0.0 a 1.0) o como `int`:\n",
        "- `float`: frecuencia de repetición máxima / mínima\n",
        "- `int`: número de repeticiones máximo / mínimo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M6rzDSsQmUiZ"
      },
      "outputs": [],
      "source": [
        "vectorizer = CountVectorizer(max_df=0.95, min_df=1)  # Jugar con los valores\n",
        "X = vectorizer.fit_transform(corpus)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(vectorizer.get_feature_names_out())"
      ],
      "metadata": {
        "id": "UyNyeRcluAGu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc_term_matrix = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())\n",
        "doc_term_matrix"
      ],
      "metadata": {
        "id": "CDNhyPnBuDCB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PqVaqn7_mUia"
      },
      "source": [
        "### TF-IDF Vectorizer\n",
        "\n",
        "TF-IDF (Term Frequency - Inverse Document Frequency) es una medida de feature weighting que expresa lo **relevante que es una palabra en un documento**, siendo este documento parte de un corpus.\n",
        "\n",
        "Tiene en cuenta el número de veces que aparece la palabra (o token) en dicho documento, pero también el total de veces que aparece en todo el corpus.\n",
        "\n",
        "- **Tokens muy frecuentes a nivel de documento y de corpus** - posibles stop words - obtendrán un valor de **TF-IDF bajo**.\n",
        "- Tokens que aparecen **solo en ciertos documentos del corpus** tendrán un **IDF mayor** que aquellos que aparecen en mayor número de documentos.\n",
        "\n",
        "<img src=https://3.bp.blogspot.com/-u928a3xbrsw/UukmRVX_JzI/AAAAAAAAAKE/wIhuNmdQb7E/s1600/td-idf-graphic.png width=700px>\n",
        "\n",
        "En un sistema de Information Retrieval sencillo, el módulo de ranking de documentos puede construirse considerando el peso de cada documento como la suma de los TF-IDF de cada palabra que lo componen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pTOl-hfSmUia"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AXl5VMqCmUia"
      },
      "outputs": [],
      "source": [
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6YQoCkocmUia"
      },
      "outputs": [],
      "source": [
        "transformer = TfidfTransformer()\n",
        "tf_idf = transformer.fit_transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer.get_feature_names_out()"
      ],
      "metadata": {
        "id": "m4_Y3kRDuGSD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc_term_matrix = pd.DataFrame(tf_idf.toarray(), columns=vectorizer.get_feature_names_out())\n",
        "doc_term_matrix"
      ],
      "metadata": {
        "id": "oO5X0ZOEuIUb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJCmKBZemUia"
      },
      "source": [
        "### TF-IDF Vectorizer (manera directa)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fpPHvbPSmUia"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer()\n",
        "tf_idf = vectorizer.fit_transform(corpus)"
      ],
      "metadata": {
        "id": "5LHoPNkUA2WI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc_term_matrix = pd.DataFrame(tf_idf.toarray(), columns=vectorizer.get_feature_names_out())\n",
        "doc_term_matrix"
      ],
      "metadata": {
        "id": "8Rdfz1fcuK0f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fafEWF7CmUib"
      },
      "source": [
        "## Ejemplo: Detección de Spam\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rIYvI47mUib"
      },
      "source": [
        "#### Lectura de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LUkfBxkrmUib"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "k7NJW2wHmUib"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('./spam.csv', encoding='latin-1')\n",
        "\n",
        "df = df[['v1', 'v2']]\n",
        "df.rename(columns={'v1': 'label', 'v2': 'sms'}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "s20PUDU7uOFg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "ZGH35Rs_uQ1m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['label'].value_counts()"
      ],
      "metadata": {
        "id": "62k4yaiHuec1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pMRIcwDmUib"
      },
      "source": [
        "#### Preprocesado"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['label'] = df['label'].map({'ham': 0, 'spam': 1})"
      ],
      "metadata": {
        "id": "tRZgZZViuiGF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "WH7WPvYMuko3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['sms'] = df['sms'].str.lower()"
      ],
      "metadata": {
        "id": "Fbs9AnuXum4o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "rPAqs16WusiI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VC1OOJzKmUic"
      },
      "source": [
        "#### Train / Test set"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "msk = np.random.rand(len(df)) < 0.75"
      ],
      "metadata": {
        "id": "jVnLYc1BuvAF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7K2PNg06mUic"
      },
      "outputs": [],
      "source": [
        "df_train = df[msk]\n",
        "df_test = df[~msk]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.shape"
      ],
      "metadata": {
        "id": "XrjWtJdauydd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test.shape"
      ],
      "metadata": {
        "id": "PwOHdp3Du1DL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLiD3h2xmUic"
      },
      "source": [
        "#### Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "88o7wWZumUic"
      },
      "outputs": [],
      "source": [
        "# CountVectorizer simple\n",
        "cv_simple = CountVectorizer()\n",
        "X_train_cv_simple = cv_simple.fit_transform(df_train['sms'])\n",
        "X_test_cv_simple = cv_simple.transform(df_test['sms'])\n",
        "\n",
        "# CountVectorizer con ngrams, max_features, min_df y max_df\n",
        "cv_complex = CountVectorizer(ngram_range=(1, 2), max_features=1000, max_df=0.95, min_df=5)\n",
        "X_train_cv_complex = cv_complex.fit_transform(df_train['sms'])\n",
        "X_test_cv_complex = cv_complex.transform(df_test['sms'])\n",
        "\n",
        "# TfIdfVectorizer simple\n",
        "tfidf_simple = TfidfVectorizer()\n",
        "X_train_tfidf_simple = tfidf_simple.fit_transform(df_train['sms'])\n",
        "X_test_tfidf_simple = tfidf_simple.transform(df_test['sms'])\n",
        "\n",
        "# TfIdfVectorizer complejo\n",
        "tfidf_complex = TfidfVectorizer(ngram_range=(1, 2), max_features=1000, max_df=0.95, min_df=5)\n",
        "X_train_tfidf_complex = tfidf_complex.fit_transform(df_train['sms'])\n",
        "X_test_tfidf_complex = tfidf_complex.transform(df_test['sms'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLLNFrEQmUic"
      },
      "source": [
        "#### Modelo de clasificación binaria"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_h6PAIkQmUic"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xIaABwf0mUic"
      },
      "outputs": [],
      "source": [
        "lr_cv_simple = LogisticRegression()\n",
        "lr_cv_complex = LogisticRegression()\n",
        "lr_tfidf_simple = LogisticRegression()\n",
        "lr_tfidf_complex = LogisticRegression()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hjU6iEpBmUid"
      },
      "outputs": [],
      "source": [
        "lr_cv_simple.fit(X_train_cv_simple, df_train['label'])  # train\n",
        "y_pred_cv_simple = lr_cv_simple.predict(X_test_cv_simple)  # test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "dHbDnHLbmUid"
      },
      "outputs": [],
      "source": [
        "lr_cv_complex.fit(X_train_cv_complex, df_train['label'])  # train\n",
        "y_pred_cv_complex = lr_cv_complex.predict(X_test_cv_complex)  # test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QA8YodOEmUid"
      },
      "outputs": [],
      "source": [
        "lr_tfidf_simple.fit(X_train_tfidf_simple, df_train['label'])  # train\n",
        "y_pred_tfidf_simple = lr_tfidf_simple.predict(X_test_tfidf_simple)  # test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q4pyGEhcmUid"
      },
      "outputs": [],
      "source": [
        "lr_tfidf_complex.fit(X_train_tfidf_complex, df_train['label'])  # train\n",
        "y_pred_tfidf_complex = lr_tfidf_complex.predict(X_test_tfidf_complex)  # test"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('CountVectorizer simple\\n')\n",
        "print(confusion_matrix(df_test['label'], y_pred_cv_simple))\n",
        "print(classification_report(df_test['label'], y_pred_cv_simple))"
      ],
      "metadata": {
        "id": "Opbo6YMFu7tP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('CountVectorizer complejo\\n')\n",
        "print(confusion_matrix(df_test['label'], y_pred_cv_complex))\n",
        "print(classification_report(df_test['label'], y_pred_cv_complex))"
      ],
      "metadata": {
        "id": "Kw68lN04u_-N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('TfIdfVectorizer simple\\n')\n",
        "print(confusion_matrix(df_test['label'], y_pred_tfidf_simple))\n",
        "print(classification_report(df_test['label'], y_pred_tfidf_simple))"
      ],
      "metadata": {
        "id": "jMPyk7SHvEZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('TfIdfVectorizer complejo\\n')\n",
        "print(confusion_matrix(df_test['label'], y_pred_tfidf_complex))\n",
        "print(classification_report(df_test['label'], y_pred_tfidf_complex))"
      ],
      "metadata": {
        "id": "WL9aja-xvHD7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFeiCq51mUid"
      },
      "source": [
        "# 3. Word Embeddings\n",
        "\n",
        "Permiten codificar la información semántica de los tokens en función del contexto (tokens anteriores y posteriores) en el que se encuentren.\n",
        "\n",
        "Cada palabra estará representada por un vector con dicha información semántica. Operaciones con vectores, y el concepto de distancia, nos permitirá encontrar tokens que semánticamente son parecidos o diferentes.\n",
        "\n",
        "Lo veremos con más detalle en la próxima sesión.\n",
        "\n",
        "<img src=https://blog.enzymeadvisinggroup.com/hs-fs/hubfs/Word%20Embeddings%20en%20el%20Natural%20Language%20Processing.png>"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}